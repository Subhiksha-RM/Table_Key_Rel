{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4445/3610541987.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "manf_df = pd.read_csv('Manufacturing_Facilities.csv')\n",
    "logh_df = pd.read_csv('Logistics_Hubs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Facility_Id Facility_name Location  Capacity    Production_item  \\\n",
      "0            1       Manuf_A        A      5000  AtomicLayerEtcher   \n",
      "1            2       Manuf_B        B      3000       PlasmaEtcher   \n",
      "2            3       Manuf_C        C      7000       WaferCleaner   \n",
      "3            4       Manuf_A        A      6000       PlasmaEtcher   \n",
      "4            5       Manuf_D        D      2000  WaferCleanChamber   \n",
      "5            6       Manuf_B        B      4500  AtomicLayerEtcher   \n",
      "\n",
      "   Utilization_rate Maintenance_status  \n",
      "0               0.8            Regular  \n",
      "1               0.6               Good  \n",
      "2               0.9               Good  \n",
      "3               0.7           Critical  \n",
      "4               0.8               Good  \n",
      "5               0.5            Regular  \n"
     ]
    }
   ],
   "source": [
    "print(manf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hub_Id Facility_Id Hub_name Location  Capacity  Throughput  \\\n",
      "0     101         1,2    Hub_X        X      8000         500   \n",
      "1     102           2    Hub_Y        Y      6000         400   \n",
      "2     103           3    Hub_Z        Z      9000         600   \n",
      "3     104           4    Hub_A        A      7000         500   \n",
      "4     105         5,6    Hub_B        B      5000         400   \n",
      "\n",
      "   Inventory_Levels  \n",
      "0              2000  \n",
      "1              1500  \n",
      "2              2500  \n",
      "3              3000  \n",
      "4              2000  \n"
     ]
    }
   ],
   "source": [
    "print(logh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No primary key constraint violation in ManuFact table.\n",
      "No primary key constraint violation in LogHub table.\n",
      "Foreign key constraint violated in LogHub table.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for duplicate Facility id in the Manufact table (Primary Key constraint)\n",
    "if manf_df.duplicated('Facility_Id').any():\n",
    "    print(\"Primary key constraint violated in ManuFact table.\")\n",
    "else:\n",
    "    print(\"No primary key constraint violation in ManuFact table.\")\n",
    "\n",
    "# Check for duplicate HubID in the LogHub table (Primary Key constraint)\n",
    "if logh_df.duplicated('Hub_Id').any():\n",
    "    print(\"Primary key constraint violated in LogHub table.\")\n",
    "else:\n",
    "    print(\"No primary key constraint violation in LogHub table.\")\n",
    "\n",
    "# Check if all FacilityIDs in the LogHub table exist in the Manufact table (Foreign Key constraint)\n",
    "if not manf_df['Facility_Id'].isin(logh_df['Hub_Id']).all():\n",
    "    print(\"Foreign key constraint violated in LogHub table.\")\n",
    "else:\n",
    "    print(\"No foreign key constraint violation in LogHub table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hub_Id Facility_Id Hub_name Location  Capacity  Throughput  \\\n",
      "0   101.0         1,2    Hub_X        X      8000       500.0   \n",
      "1   102.0           2    Hub_Y        Y      6000       400.0   \n",
      "2   103.0           3    Hub_Z        Z      9000       600.0   \n",
      "3   104.0           4    Hub_A        A      7000       500.0   \n",
      "4   105.0         5,6    Hub_B        B      5000       400.0   \n",
      "0     NaN           1      NaN        A      5000         NaN   \n",
      "1     NaN           2      NaN        B      3000         NaN   \n",
      "2     NaN           3      NaN        C      7000         NaN   \n",
      "3     NaN           4      NaN        A      6000         NaN   \n",
      "4     NaN           5      NaN        D      2000         NaN   \n",
      "5     NaN           6      NaN        B      4500         NaN   \n",
      "\n",
      "   Inventory_Levels Facility_name    Production_item  Utilization_rate  \\\n",
      "0            2000.0           NaN                NaN               NaN   \n",
      "1            1500.0           NaN                NaN               NaN   \n",
      "2            2500.0           NaN                NaN               NaN   \n",
      "3            3000.0           NaN                NaN               NaN   \n",
      "4            2000.0           NaN                NaN               NaN   \n",
      "0               NaN       Manuf_A  AtomicLayerEtcher               0.8   \n",
      "1               NaN       Manuf_B       PlasmaEtcher               0.6   \n",
      "2               NaN       Manuf_C       WaferCleaner               0.9   \n",
      "3               NaN       Manuf_A       PlasmaEtcher               0.7   \n",
      "4               NaN       Manuf_D  WaferCleanChamber               0.8   \n",
      "5               NaN       Manuf_B  AtomicLayerEtcher               0.5   \n",
      "\n",
      "  Maintenance_status  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "0            Regular  \n",
      "1               Good  \n",
      "2               Good  \n",
      "3           Critical  \n",
      "4               Good  \n",
      "5            Regular  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate DataFrames along rows axis (index)\n",
    "concatenated_df = pd.concat([logh_df, manf_df])\n",
    "\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary key '101.0' has multiple foreign keys: 1,2\n",
      "Primary key '102.0' has multiple foreign keys: 2\n",
      "Primary key '103.0' has multiple foreign keys: 3\n",
      "Primary key '104.0' has multiple foreign keys: 4\n",
      "Primary key '105.0' has multiple foreign keys: 5,6\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'primary_key_column' is the primary key column name and 'foreign_key_column' is the foreign key column name\n",
    "primary_key_column = 'Hub_Id'\n",
    "foreign_key_column = 'Facility_Id'\n",
    "\n",
    "# Concatenate DataFrames along rows axis (index)\n",
    "concatenated_df = pd.concat([logh_df, manf_df])\n",
    "#print(concatenated_df)\n",
    "\n",
    "# Group by primary key column\n",
    "groups = concatenated_df.groupby(primary_key_column)\n",
    "\n",
    "# Initialize an empty dictionary to store primary keys with multiple foreign keys\n",
    "primary_multiple_foreign_keys = {}\n",
    "\n",
    "# Iterate through groups\n",
    "for primary_key, group_df in groups:\n",
    "    foreign_keys = group_df[foreign_key_column].unique()\n",
    "    #print(group_df)\n",
    "    #print(foreign_keys)\n",
    "    if len(foreign_keys) >=1:\n",
    "        primary_multiple_foreign_keys[primary_key] = foreign_keys\n",
    "        #print(primary_multiple_foreign_keys)\n",
    "\n",
    "# Print primary keys with multiple foreign keys\n",
    "for primary_key, foreign_keys in primary_multiple_foreign_keys.items():\n",
    "    print(f\"Primary key '{primary_key}' has multiple foreign keys: {', '.join(map(str, foreign_keys))}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hub_Id Facility_Id\n",
      "0   101.0         1,2\n",
      "1   102.0           2\n",
      "2   103.0           3\n",
      "3   104.0           4\n",
      "4   105.0         5,6\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'primary_key_column' is the primary key column name and 'foreign_key_column' is the foreign key column name\n",
    "primary_key_column = 'Hub_Id'\n",
    "foreign_key_column = 'Facility_Id'\n",
    "\n",
    "# Concatenate DataFrames along rows axis (index)\n",
    "concatenated_df = pd.concat([logh_df, manf_df])\n",
    "#print(concatenated_df)\n",
    "\n",
    "# Group by primary key column\n",
    "groups = concatenated_df.groupby(primary_key_column)\n",
    "\n",
    "# Initialize an empty list to store primary keys with multiple foreign keys as well as single foreign keys\n",
    "rows_foreign_keys = []\n",
    "# Iterate through groups\n",
    "for primary_key, group_df in groups:\n",
    "    foreign_keys = group_df[foreign_key_column].unique()\n",
    "    if len(foreign_keys) >= 1:\n",
    "        rows_foreign_keys.append({'Hub_Id': primary_key, 'Facility_Id': ', '.join(map(str, foreign_keys))})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df_multiple_foreign_keys = pd.DataFrame(rows_foreign_keys)\n",
    "\n",
    "# Print the DataFrame containing primary keys with multiple foreign keys\n",
    "print(df_multiple_foreign_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2\n",
      "2\n",
      "3\n",
      "4\n",
      "5,6\n"
     ]
    }
   ],
   "source": [
    "for foreign_keys in df_multiple_foreign_keys['Foreign_Keys']:\n",
    "    keys = foreign_keys.split(', ')\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary key '101.0' is associated with foreign key '1'\n",
      "Primary key '101.0' is associated with foreign key '2'\n",
      "Primary key '102.0' is associated with foreign key '2'\n",
      "Primary key '103.0' is associated with foreign key '3'\n",
      "Primary key '104.0' is associated with foreign key '4'\n",
      "Primary key '105.0' is associated with foreign key '5'\n",
      "Primary key '105.0' is associated with foreign key '6'\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the DataFrame and print each primary key with each associated foreign key separately\n",
    "for index, row in df_multiple_foreign_keys.iterrows():\n",
    "    primary_key = row['Primary_Key']\n",
    "    foreign_keys = [key.strip() for key in row['Foreign_Keys'].split(',')]\n",
    "    for foreign_key in foreign_keys:\n",
    "        print(f\"Primary key '{primary_key}' is associated with foreign key '{foreign_key}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hub_Id Facility_Id\n",
      "0   101.0           1\n",
      "1   101.0           2\n",
      "2   102.0           2\n",
      "3   103.0           3\n",
      "4   104.0           4\n",
      "5   105.0           5\n",
      "6   105.0           6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store combinations of primary key and foreign key\n",
    "combined_data = []\n",
    "\n",
    "# Iterate through the DataFrame and collect combinations\n",
    "for index, row in df_multiple_foreign_keys.iterrows():\n",
    "    primary_key = row['Hub_Id']\n",
    "    foreign_keys = [key.strip() for key in row['Facility_Id'].split(',')]\n",
    "    for foreign_key in foreign_keys:\n",
    "        combined_data.append({'Hub_Id': primary_key, 'Facility_Id': foreign_key})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
